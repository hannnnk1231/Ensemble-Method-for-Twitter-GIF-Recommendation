{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XLNET.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "073ac9b7dca24c64901109270f237d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7b2619e0b32340c68c8fde7f9e76faec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ab7ce8dfd8c743a180625fe54eb72a80",
              "IPY_MODEL_2f299ab1513d4041ba26fa2c28d5d2fa"
            ]
          }
        },
        "7b2619e0b32340c68c8fde7f9e76faec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab7ce8dfd8c743a180625fe54eb72a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_76042d020ab644f7b82e8295e7b80843",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 798011,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 798011,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6862e620ac4d4caebe9e8430ca197720"
          }
        },
        "2f299ab1513d4041ba26fa2c28d5d2fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2a76e2d367d641fdb00dc6022be98e6c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 798k/798k [00:00&lt;00:00, 2.78MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_654d25fa9dea4420a8b2b6321cec695c"
          }
        },
        "76042d020ab644f7b82e8295e7b80843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6862e620ac4d4caebe9e8430ca197720": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a76e2d367d641fdb00dc6022be98e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "654d25fa9dea4420a8b2b6321cec695c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4881d21ecac5468884d189cf702bb448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a48fb94c1c5b4667a45a8388dfb4f0f7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f6ca3678f2b34f4c96315e3b88b708d8",
              "IPY_MODEL_a0249d49247c4c17874fd3fe408c65ec"
            ]
          }
        },
        "a48fb94c1c5b4667a45a8388dfb4f0f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6ca3678f2b34f4c96315e3b88b708d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_24e1aa0fc420480cbee2f0f56030c393",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 761,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 761,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0fd3436d31a14e599be84dd80f068b9c"
          }
        },
        "a0249d49247c4c17874fd3fe408c65ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_42093061640b41bab4f5336fa3f7b0e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 761/761 [00:00&lt;00:00, 2.36kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76e452e5cffe449d9c537ce798a1ab0e"
          }
        },
        "24e1aa0fc420480cbee2f0f56030c393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0fd3436d31a14e599be84dd80f068b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42093061640b41bab4f5336fa3f7b0e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76e452e5cffe449d9c537ce798a1ab0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4286fb4eac924a16a8b318ea3d829450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1d93b7df2d7a4130b76070c8a5d1f406",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_012682670a8e4dfabdd226062e7b4eee",
              "IPY_MODEL_64a3e179cd9b4d11bccfb3c90939e9fc"
            ]
          }
        },
        "1d93b7df2d7a4130b76070c8a5d1f406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "012682670a8e4dfabdd226062e7b4eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_61f2f324b7b04003892fe60aed04f488",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1572621064,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1572621064,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6effcf865d704a4d8b9f91115d1ae7d5"
          }
        },
        "64a3e179cd9b4d11bccfb3c90939e9fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f45c1dd1ad09473c9160bf8c79792f8d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.57G/1.57G [00:21&lt;00:00, 73.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_435f325b3c6c41bb848ab481d6bbe464"
          }
        },
        "61f2f324b7b04003892fe60aed04f488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6effcf865d704a4d8b9f91115d1ae7d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f45c1dd1ad09473c9160bf8c79792f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "435f325b3c6c41bb848ab481d6bbe464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "afYXUf-Q0yT1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74e73461-f5d4-4aa1-ec9e-533a8b324b78"
      },
      "source": [
        "'''from google.colab import files\n",
        "uploaded = files.upload()'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from google.colab import files\\nuploaded = files.upload()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY4tQg9BY8mH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "5e8c1723-93e3-4f67-8c61-0cc6cfda614c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun 23 14:27:23 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KFZbLzFZyOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/content/drive/My Drive/NLP/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRkIKpaN0xT4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "0097d8e3-378c-46d2-ade3-93a40c87b4ec"
      },
      "source": [
        "import pandas as pd, numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "!pip install transformers\n",
        "from transformers import *\n",
        "import tokenizers\n",
        "print('TF version',tf.__version__)\n",
        "!pip install emoji\n",
        "import emoji\n",
        "import re\n",
        "import math\n",
        "import keras\n",
        "import json\n",
        "import string\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "TF version 2.2.0\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (0.5.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTRczysC09AN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(PATH+'categories.json') as f:\n",
        "  categories = json.load(f)\n",
        "\n",
        "tweets = []\n",
        "for line in open(PATH+'train_gold.json', 'r'):\n",
        "    tweets.append(json.loads(line))\n",
        "\n",
        "test = []\n",
        "for line in open(PATH+'test_unlabeled.json', 'r'):\n",
        "    test.append(json.loads(line))\n",
        "    \n",
        "dev = []\n",
        "for line in open(PATH+'dev_unlabeled.json','r'):\n",
        "  dev.append(json.loads(line))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSYpNsYIc5TM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(PATH+\"weird.txt\")\n",
        "weird = f.read().splitlines()\n",
        "#print(weird)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLa0w58p1xkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rule(token):\n",
        "    '''\n",
        "    Remove tokens with\n",
        "    x. stop words  Ex. the, we (Update: only rmv '️')\n",
        "    2. punctuation Ex. !!\n",
        "    3. numbers     Ex. 1kg\n",
        "    4. hashtags    Ex. #NLP\n",
        "    5. tags        Ex. @hannnnk\n",
        "    6. hyper link  Ex. https://...\n",
        "    '''\n",
        "    return True if token not in stopword and \\\n",
        "                   token not in punctuation and \\\n",
        "                   \"\\n\" not in token and \\\n",
        "                   not re.search('\\d+', token) and \\\n",
        "                   not token.startswith('#') and \\\n",
        "                   not token.startswith('@') and \\\n",
        "                   not token.startswith('https:') \\\n",
        "                   else False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-lezO9u3PND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean(tweet):\n",
        "    tweet = re.sub(r\"what's\", \"what is\", tweet)\n",
        "    tweet = re.sub(r\"we'll\", \"we will\", tweet)\n",
        "    tweet = re.sub(r\"who's\", \"who is\", tweet)\n",
        "    tweet = re.sub(r\"here's\", \"here is\", tweet)\n",
        "    tweet = re.sub(r\"today's\", \"today is\", tweet)\n",
        "    tweet = re.sub(r\"ain't\", \"are not\", tweet)\n",
        "    tweet = re.sub(r\"we've\", \"we have\", tweet)\n",
        "    tweet = re.sub(r\"how's\", \"how is\", tweet)\n",
        "    tweet = re.sub(r\"thet've\", \"they have\", tweet)\n",
        "    tweet = re.sub(r\"it'll\", \"it will\", tweet)\n",
        "    tweet = re.sub(r\"ya'll\", \"you all\", tweet)\n",
        "    tweet = re.sub(r\"i'm\", \"i am\", tweet)\n",
        "    tweet = re.sub(r\"don't\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"it's\", \"it is\", tweet)\n",
        "    tweet = re.sub(r\"you're\", \"you are\", tweet)\n",
        "    tweet = re.sub(r\"can't\", \"cannot\", tweet)\n",
        "    tweet = re.sub(r\"i've\", \"i have\", tweet)\n",
        "    tweet = re.sub(r\"that's\", \"that is\", tweet)\n",
        "    tweet = re.sub(r\"we're\", \"we are\", tweet)\n",
        "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"he's\", \"he is\", tweet)\n",
        "    tweet = re.sub(r\"let's\", \"let us\", tweet)\n",
        "    tweet = re.sub(r\"didn't\", \"did not\", tweet)\n",
        "    tweet = re.sub(r\"y'all\", \"you all\", tweet)\n",
        "    tweet = re.sub(r\"doesn't\", \"does not\", tweet)\n",
        "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"who-the-hell-even-knows-anymore\", \"who the hell even knows anymore\", tweet)\n",
        "    tweet = re.sub(r\"there's\", \"there is\", tweet)\n",
        "    tweet = re.sub(r\"isn't\", \"is not\", tweet)\n",
        "    tweet = re.sub(r\"won't\", \"will not\", tweet)\n",
        "    tweet = re.sub(r\"they're\", \"they are\", tweet)\n",
        "    tweet = re.sub(r\"haven't\", \"have not\", tweet)\n",
        "    tweet = re.sub(r\"couldn't\", \"could not\", tweet)\n",
        "    tweet = re.sub(r\"she's\", \"she is\", tweet)\n",
        "    tweet = re.sub(r\"aren't\", \"are not\", tweet)\n",
        "    tweet = re.sub(r\"you've\", \"you have\", tweet)\n",
        "    tweet = re.sub(r\"you'll\", \"you will\", tweet)\n",
        "    tweet = re.sub(r\"wouldn't\", \"would not\", tweet)\n",
        "    tweet = re.sub(r\"wasn't\", \"was not\", tweet)\n",
        "    tweet = re.sub(r\"shouldn't\", \"shoud not\", tweet)  \n",
        "    tweet = re.sub(r\"they'll\", \"they will\", tweet)\n",
        "    tweet = re.sub(r\"weren't\", \"were not\", tweet)\n",
        "    tweet = re.sub(r\"you'd\", \"you had\", tweet)\n",
        "    tweet = re.sub(r\"they've\", \"they have\", tweet)\n",
        "    tweet = re.sub(r\"no-excuse\", \"no excuse\", tweet)\n",
        "    tweet = re.sub(r\"vote-by-mail\", \"vote by mail\", tweet)\n",
        "    tweet = re.sub(r\"votesafe\", \"vote safe\", tweet)\n",
        "    tweet = re.sub(r\"lmaoooo\", \"laugh my ass off\", tweet)\n",
        "    tweet = re.sub(r\"we'd\", \"we had\", tweet)\n",
        "    tweet = re.sub(r\"he'll\", \"he will\", tweet)\n",
        "    tweet = re.sub(r\"he'd\", \"he had\", tweet)\n",
        "    tweet = re.sub(r\"would've\", \"would have\", tweet)\n",
        "    tweet = re.sub(r\"hadn't\", \"had not\", tweet)\n",
        "    tweet = re.sub(r\"diefrom\", \"die from\", tweet)\n",
        "    tweet = re.sub(r\"dababy\", \"rapper\", tweet)\n",
        "    tweet = re.sub(r\"hasn't\", \"has not\", tweet)\n",
        "    tweet = re.sub(r\"testing-based\", \"testing based\", tweet)\n",
        "    tweet = re.sub(r\"that'll\", \"that will\", tweet)\n",
        "    tweet = re.sub(r\"should've\", \"should have\", tweet)\n",
        "    tweet = re.sub(r\"cashapp\", \"cash app\", tweet)\n",
        "    tweet = re.sub(r\"brexit-induced\", \"brexit induced\", tweet)\n",
        "    tweet = re.sub(r\"president-hating\", \"president hating\", tweet)\n",
        "    tweet = re.sub(r\"picked-over\", \"picked over\", tweet)\n",
        "    \n",
        "    tweet = re.sub(r\"what’s\", \"what is\", tweet)\n",
        "    tweet = re.sub(r\"we’ll\", \"we will\", tweet)\n",
        "    tweet = re.sub(r\"who’s\", \"who is\", tweet)\n",
        "    tweet = re.sub(r\"here’s\", \"here is\", tweet)\n",
        "    tweet = re.sub(r\"today’s\", \"today is\", tweet)\n",
        "    tweet = re.sub(r\"ain’t\", \"are not\", tweet)\n",
        "    tweet = re.sub(r\"we’ve\", \"we have\", tweet)\n",
        "    tweet = re.sub(r\"how’s\", \"how is\", tweet)\n",
        "    tweet = re.sub(r\"thet’ve\", \"they have\", tweet)\n",
        "    tweet = re.sub(r\"it’ll\", \"it will\", tweet)\n",
        "    tweet = re.sub(r\"ya’ll\", \"you all\", tweet)\n",
        "    tweet = re.sub(r\"i’m\", \"i am\", tweet)\n",
        "    tweet = re.sub(r\"don’t\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"it’s\", \"it is\", tweet)\n",
        "    tweet = re.sub(r\"you’re\", \"you are\", tweet)\n",
        "    tweet = re.sub(r\"can’t\", \"cannot\", tweet)\n",
        "    tweet = re.sub(r\"i’ve\", \"i have\", tweet)\n",
        "    tweet = re.sub(r\"that’s\", \"that is\", tweet)\n",
        "    tweet = re.sub(r\"we’re\", \"we are\", tweet)\n",
        "    tweet = re.sub(r\"i’ll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"he’s\", \"he is\", tweet)\n",
        "    tweet = re.sub(r\"let’s\", \"let us\", tweet)\n",
        "    tweet = re.sub(r\"didn’t\", \"did not\", tweet)\n",
        "    tweet = re.sub(r\"y’all\", \"you all\", tweet)\n",
        "    tweet = re.sub(r\"doesn’t\", \"does not\", tweet)\n",
        "    tweet = re.sub(r\"i’d\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"there’s\", \"there is\", tweet)\n",
        "    tweet = re.sub(r\"isn’t\", \"is not\", tweet)\n",
        "    tweet = re.sub(r\"won’t\", \"will not\", tweet)\n",
        "    tweet = re.sub(r\"they’re\", \"they are\", tweet)\n",
        "    tweet = re.sub(r\"haven’t\", \"have not\", tweet)\n",
        "    tweet = re.sub(r\"couldn’t\", \"could not\", tweet)\n",
        "    tweet = re.sub(r\"she’s\", \"she is\", tweet)\n",
        "    tweet = re.sub(r\"aren’t\", \"are not\", tweet)\n",
        "    tweet = re.sub(r\"you’ve\", \"you have\", tweet)\n",
        "    tweet = re.sub(r\"you’ll\", \"you will\", tweet)\n",
        "    tweet = re.sub(r\"wouldn’t\", \"would not\", tweet)\n",
        "    tweet = re.sub(r\"wasn’t\", \"was not\", tweet)\n",
        "    tweet = re.sub(r\"shouldn’t\", \"shoud not\", tweet)\n",
        "    tweet = re.sub(r\"they’ll\", \"they will\", tweet)\n",
        "    tweet = re.sub(r\"weren’t\", \"were not\", tweet)\n",
        "    tweet = re.sub(r\"you’d\", \"you had\", tweet)\n",
        "    tweet = re.sub(r\"they’ve\", \"they have\", tweet)\n",
        "    tweet = re.sub(r\"we’d\", \"we had\", tweet)\n",
        "    tweet = re.sub(r\"he’ll\", \"he will\", tweet)\n",
        "    tweet = re.sub(r\"he’d\", \"he had\", tweet)\n",
        "    tweet = re.sub(r\"would’ve\", \"would have\", tweet)\n",
        "    tweet = re.sub(r\"hadn’t\", \"had not\", tweet)\n",
        "    tweet = re.sub(r\"hasn’t\", \"has not\", tweet)\n",
        "    tweet = re.sub(r\"that’ll\", \"that will\", tweet)\n",
        "    tweet = re.sub(r\"should’ve\", \"should have\", tweet)\n",
        "    \n",
        "    return tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq5oQvWA5geK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "tknzr = TweetTokenizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o1IK7445r-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopword = ['️']\n",
        "punctuation = string.punctuation+'“’”...—…‼‘'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzwr5zBm3-81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for t in tweets:\n",
        "    t['text'] = clean(t['text'].lower())\n",
        "    t['reply'] = clean(t['reply'].lower())\n",
        "for t in dev:\n",
        "    t['text'] = clean(t['text'].lower())\n",
        "    t['reply'] = clean(t['reply'].lower())\n",
        "for t in test:\n",
        "    t['text'] = clean(t['text'].lower())\n",
        "    t['reply'] = clean(t['reply'].lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dRGLcS-4yvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for t in tweets:\n",
        "    temp = [token.lower() for token in tknzr.tokenize(t['text']) if rule(token.lower())]\n",
        "    temp2 = [token.lower() for token in tknzr.tokenize(t['reply']) if rule(token.lower())]\n",
        "\n",
        "    t['text_clean'] = temp\n",
        "    t['reply_clean'] = temp2\n",
        "\n",
        "for t in dev:\n",
        "    temp = [token.lower() for token in tknzr.tokenize(t['text']) if rule(token.lower())]\n",
        "    temp2 = [token.lower() for token in tknzr.tokenize(t['reply']) if rule(token.lower())]\n",
        "\n",
        "    t['text_clean'] = temp\n",
        "    t['reply_clean'] = temp2\n",
        "    \n",
        "for t in test:\n",
        "    temp = [token.lower() for token in tknzr.tokenize(t['text']) if rule(token.lower())]\n",
        "    temp2 = [token.lower() for token in tknzr.tokenize(t['reply']) if rule(token.lower())]\n",
        "\n",
        "    t['text_clean'] = temp\n",
        "    t['reply_clean'] = temp2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3lI5gCo6MIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Deal with special words for embedding such as\n",
        "covid  (806) → coronavirus\n",
        "'''\n",
        "special = {\n",
        "    'covid':'coronavirus',\n",
        "    \"ventilators\":\"ventilator\",\n",
        "    \"virologist\":'virology',\n",
        "    'fauci':'physician',\n",
        "    \"onlyfans\":\"app\",\n",
        "    \"fortnite\":\"game\",\n",
        "    \"valorant\":\"game\",\n",
        "    \"jeudy\":\"athlete\",\n",
        "    \"ruggs\":\"athlete\",\n",
        "    \"tagovailoa\":\"athlete\",\n",
        "    \"rashford\":\"athlete\",\n",
        "    \"birx\":\"doctor\",\n",
        "    \"blaqbonez\":\"rapper\",\n",
        "    'mcsally':\"politician\",\n",
        "    \"intubated\":\"intubation\",\n",
        "    \"hydroxychloroquine\":\"medication\",\n",
        "    \"today's\":\"today\",\n",
        "    \"pubg\":\"game\",\n",
        "    \"government's\":'government',\n",
        "    \"man's\":'man',\n",
        "    \"someone's\":'someone',\n",
        "    \"country's\":'country',\n",
        "    \"everyone's\":'everyone',\n",
        "    \"people's\":'people',\n",
        "    \"club's\":'club',\n",
        "    \"china's\":'china',\n",
        "    \"america's\":'america',\n",
        "    \"world's\":'world',\n",
        "    \"life's\":'life',\n",
        "    \"earth's\":'earth',\n",
        "    \"mom's\":'mom',\n",
        "    '<3':'❤',\n",
        "    ':)':\"🙂\",\n",
        "    \":(\":\"😞\",\n",
        "    \"):\":\"😞\",\n",
        "    \":/\":\"😕\",\n",
        "    \"pre-covid\":'coronavirus',\n",
        "    \"strategise\":\"strategies\",\n",
        "    'stratagy':'strategy',\n",
        "    \"strategiser\":\"strategy\",\n",
        "    \"stratagised\":\"strategy\",\n",
        "    'ohhhh':\"ohhh\",\n",
        "    'yesssss':\"yes\",\n",
        "    'youuu':'you',\n",
        "    'sirrr':'sir',\n",
        "    'ohhhhh':'ohhh',\n",
        "    'youuuu':'you',\n",
        "    'lmaooooo':'lamo',\n",
        "    'guysss':'guys',\n",
        "    'meeeee':'me',\n",
        "    'yessss':'yes',\n",
        "    'lieeeeeee':'lie',\n",
        "    'youuuuu':'you',\n",
        "    'yesssssss':'yes',\n",
        "    'lollll':'lol',\n",
        "    'plzzzz':'plz',\n",
        "    'enddddddd':'end',\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBsGF4vX4GSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emoji_remain_text = ['😭','❤','👏','😊','😔','🙏','🙃','💜','👍','🙌','😁','🤗','💔','☹','😎','😢','💛','💖','💰','💯','💗','💪','😞','😣',\"🙂\",\"😞\",\"😕\"]\n",
        "emoji_remain_reply = ['❤','🙏','😭','👏','💜','👍','🤗','💕','💖','😘','💙','♥','💞','🙌','💗','😉','💛','🤦','💓','🖤','🙄','💯','☺','💃','🎉','😔','💚','💔','✨','😢','🌹',\"🙂\",\"😞\",\"😕\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSjcNiSd6c8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rule_emoji_text(token, emoji_remain):\n",
        "    if len(token)==1:\n",
        "        if ord(token)>122:\n",
        "            if token not in emoji_remain:\n",
        "              return False\n",
        "    return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7JIDf5p6ZY3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ebc23f2-7bd1-407b-8e97-fca2a41f8416"
      },
      "source": [
        "tokens = Counter()\n",
        "tokens2 = Counter()\n",
        "for t in tweets:\n",
        "    temp = [token for token in t['text_clean'] if rule_emoji_text(token,emoji_remain_text)]\n",
        "    t['text_clean'] = temp\n",
        "    tokens.update(temp)\n",
        "    temp2 = [token for token in t['reply_clean'] if rule_emoji_text(token,emoji_remain_reply)]\n",
        "    for idx,token in enumerate(temp2):\n",
        "        if token == '🥺':\n",
        "            temp2[idx] = '❤'\n",
        "    t['reply_clean'] = temp2\n",
        "    tokens2.update(temp2)\n",
        "    \n",
        "temp = pd.DataFrame(tokens.most_common(30))\n",
        "temp.columns = ['tokens_main','count']\n",
        "display(temp.style.background_gradient(cmap='Blues'))\n",
        "temp2 = pd.DataFrame(tokens2.most_common(30))\n",
        "temp2.columns = ['tokens_reply','count']\n",
        "display(temp2.style.background_gradient(cmap='Reds'))\n",
        "\n",
        "for t in dev:\n",
        "    temp = [token for token in t['text_clean'] if rule_emoji_text(token,emoji_remain_text)]\n",
        "    t['text_clean'] = temp\n",
        "    temp2 = [token for token in t['reply_clean'] if rule_emoji_text(token,emoji_remain_reply)]\n",
        "    for idx,token in enumerate(temp2):\n",
        "        if token == '🥺':\n",
        "            temp2[idx] = '❤'\n",
        "    t['reply_clean'] = temp2\n",
        "    \n",
        "for t in test:\n",
        "    temp = [token for token in t['text_clean'] if rule_emoji_text(token,emoji_remain_text)]\n",
        "    t['text_clean'] = temp\n",
        "    temp2 = [token for token in t['reply_clean'] if rule_emoji_text(token,emoji_remain_reply)]\n",
        "    for idx,token in enumerate(temp2):\n",
        "        if token == '🥺':\n",
        "            temp2[idx] = '❤'\n",
        "    t['reply_clean'] = temp2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row0_col1 {\n",
              "            background-color:  #08306b;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row1_col1 {\n",
              "            background-color:  #1562a9;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row2_col1 {\n",
              "            background-color:  #2777b8;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row3_col1 {\n",
              "            background-color:  #4896c8;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row4_col1 {\n",
              "            background-color:  #75b4d8;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row5_col1 {\n",
              "            background-color:  #77b5d9;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row6_col1 {\n",
              "            background-color:  #85bcdc;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row7_col1 {\n",
              "            background-color:  #b5d4e9;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row8_col1 {\n",
              "            background-color:  #cadef0;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row9_col1 {\n",
              "            background-color:  #ccdff1;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row10_col1 {\n",
              "            background-color:  #cee0f2;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row11_col1 {\n",
              "            background-color:  #cfe1f2;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row12_col1 {\n",
              "            background-color:  #d3e3f3;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row13_col1 {\n",
              "            background-color:  #dae8f6;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row14_col1 {\n",
              "            background-color:  #ddeaf7;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row15_col1 {\n",
              "            background-color:  #e3eef8;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row16_col1 {\n",
              "            background-color:  #e3eef8;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row17_col1 {\n",
              "            background-color:  #e3eef9;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row18_col1 {\n",
              "            background-color:  #e7f1fa;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row19_col1 {\n",
              "            background-color:  #e9f2fa;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row20_col1 {\n",
              "            background-color:  #ebf3fb;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row21_col1 {\n",
              "            background-color:  #eef5fc;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row22_col1 {\n",
              "            background-color:  #f2f7fd;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row23_col1 {\n",
              "            background-color:  #f3f8fe;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row24_col1 {\n",
              "            background-color:  #f4f9fe;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row25_col1 {\n",
              "            background-color:  #f4f9fe;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row26_col1 {\n",
              "            background-color:  #f5f9fe;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row27_col1 {\n",
              "            background-color:  #f7fbff;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row28_col1 {\n",
              "            background-color:  #f7fbff;\n",
              "            color:  #000000;\n",
              "        }    #T_b67fc71c_b55d_11ea_a504_0242ac1c0002row29_col1 {\n",
              "            background-color:  #f7fbff;\n",
              "            color:  #000000;\n",
              "        }</style><table id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >tokens_main</th>        <th class=\"col_heading level0 col1\" >count</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row0_col0\" class=\"data row0 col0\" >i</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row0_col1\" class=\"data row0 col1\" >22433</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row1_col0\" class=\"data row1 col0\" >the</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row1_col1\" class=\"data row1 col1\" >18746</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row2_col0\" class=\"data row2 col0\" >to</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row2_col1\" class=\"data row2 col1\" >17175</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row3_col0\" class=\"data row3 col0\" >a</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row3_col1\" class=\"data row3 col1\" >14900</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row4_col0\" class=\"data row4 col0\" >and</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row4_col1\" class=\"data row4 col1\" >12369</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row5_col0\" class=\"data row5 col0\" >is</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row5_col1\" class=\"data row5 col1\" >12307</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row6_col0\" class=\"data row6 col0\" >you</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row6_col1\" class=\"data row6 col1\" >11669</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row7_col0\" class=\"data row7 col0\" >of</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row7_col1\" class=\"data row7 col1\" >9100</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row8_col0\" class=\"data row8 col0\" >my</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row8_col1\" class=\"data row8 col1\" >7713</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row9_col0\" class=\"data row9 col0\" >in</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row9_col1\" class=\"data row9 col1\" >7540</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row10_col0\" class=\"data row10 col0\" >it</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row10_col1\" class=\"data row10 col1\" >7355</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row11_col0\" class=\"data row11 col0\" >not</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row11_col1\" class=\"data row11 col1\" >7269</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row12_col0\" class=\"data row12 col0\" >for</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row12_col1\" class=\"data row12 col1\" >6855</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row13_col0\" class=\"data row13 col0\" >that</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row13_col1\" class=\"data row13 col1\" >6095</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row14_col0\" class=\"data row14 col0\" >are</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row14_col1\" class=\"data row14 col1\" >5793</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row15_col0\" class=\"data row15 col0\" >have</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row15_col1\" class=\"data row15 col1\" >5272</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row16_col0\" class=\"data row16 col0\" >me</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row16_col1\" class=\"data row16 col1\" >5269</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row17_col0\" class=\"data row17 col0\" >am</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row17_col1\" class=\"data row17 col1\" >5263</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row18_col0\" class=\"data row18 col0\" >this</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row18_col1\" class=\"data row18 col1\" >4824</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row19_col0\" class=\"data row19 col0\" >on</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row19_col1\" class=\"data row19 col1\" >4726</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row20_col0\" class=\"data row20 col0\" >do</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row20_col1\" class=\"data row20 col1\" >4514</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row21_col0\" class=\"data row21 col0\" >be</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row21_col1\" class=\"data row21 col1\" >4230</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row22_col0\" class=\"data row22 col0\" >all</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row22_col1\" class=\"data row22 col1\" >3870</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row23_col0\" class=\"data row23 col0\" >with</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row23_col1\" class=\"data row23 col1\" >3759</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row24_col0\" class=\"data row24 col0\" >your</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row24_col1\" class=\"data row24 col1\" >3691</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row25_col0\" class=\"data row25 col0\" >we</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row25_col1\" class=\"data row25 col1\" >3676</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row26_col0\" class=\"data row26 col0\" >just</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row26_col1\" class=\"data row26 col1\" >3596</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row27_col0\" class=\"data row27 col0\" >so</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row27_col1\" class=\"data row27 col1\" >3381</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row28_col0\" class=\"data row28 col0\" >if</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row28_col1\" class=\"data row28 col1\" >3334</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row29_col0\" class=\"data row29 col0\" >will</td>\n",
              "                        <td id=\"T_b67fc71c_b55d_11ea_a504_0242ac1c0002row29_col1\" class=\"data row29 col1\" >3327</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f92ba8f6be0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row0_col1 {\n",
              "            background-color:  #67000d;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row1_col1 {\n",
              "            background-color:  #880811;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row2_col1 {\n",
              "            background-color:  #e32f27;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row3_col1 {\n",
              "            background-color:  #f75c41;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row4_col1 {\n",
              "            background-color:  #fb7050;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row5_col1 {\n",
              "            background-color:  #fb7757;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row6_col1 {\n",
              "            background-color:  #fc8565;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row7_col1 {\n",
              "            background-color:  #fca082;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row8_col1 {\n",
              "            background-color:  #fcb89e;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row9_col1 {\n",
              "            background-color:  #fcc1a8;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row10_col1 {\n",
              "            background-color:  #fdcab5;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row11_col1 {\n",
              "            background-color:  #fdcab5;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row12_col1 {\n",
              "            background-color:  #fdccb8;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row13_col1 {\n",
              "            background-color:  #fdcebb;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row14_col1 {\n",
              "            background-color:  #fedecf;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row15_col1 {\n",
              "            background-color:  #fee1d4;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row16_col1 {\n",
              "            background-color:  #fee2d5;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row17_col1 {\n",
              "            background-color:  #fee5d8;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row18_col1 {\n",
              "            background-color:  #fee8dd;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row19_col1 {\n",
              "            background-color:  #fee8dd;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row20_col1 {\n",
              "            background-color:  #fee8dd;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row21_col1 {\n",
              "            background-color:  #ffece4;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row22_col1 {\n",
              "            background-color:  #ffeee6;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row23_col1 {\n",
              "            background-color:  #ffeee7;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row24_col1 {\n",
              "            background-color:  #fff0e8;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row25_col1 {\n",
              "            background-color:  #fff0e9;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row26_col1 {\n",
              "            background-color:  #fff2ec;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row27_col1 {\n",
              "            background-color:  #fff3ed;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row28_col1 {\n",
              "            background-color:  #fff5f0;\n",
              "            color:  #000000;\n",
              "        }    #T_b6862c74_b55d_11ea_a504_0242ac1c0002row29_col1 {\n",
              "            background-color:  #fff5f0;\n",
              "            color:  #000000;\n",
              "        }</style><table id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >tokens_reply</th>        <th class=\"col_heading level0 col1\" >count</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row0_col0\" class=\"data row0 col0\" >i</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row0_col1\" class=\"data row0 col1\" >3620</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row1_col0\" class=\"data row1 col0\" >you</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row1_col1\" class=\"data row1 col1\" >3411</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row2_col0\" class=\"data row2 col0\" >the</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row2_col1\" class=\"data row2 col1\" >2588</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row3_col0\" class=\"data row3 col0\" >to</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row3_col1\" class=\"data row3 col1\" >2197</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row4_col0\" class=\"data row4 col0\" >is</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row4_col1\" class=\"data row4 col1\" >2025</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row5_col0\" class=\"data row5 col0\" >a</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row5_col1\" class=\"data row5 col1\" >1952</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row6_col0\" class=\"data row6 col0\" >and</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row6_col1\" class=\"data row6 col1\" >1819</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row7_col0\" class=\"data row7 col0\" >it</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row7_col1\" class=\"data row7 col1\" >1562</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row8_col0\" class=\"data row8 col0\" >not</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row8_col1\" class=\"data row8 col1\" >1340</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row9_col0\" class=\"data row9 col0\" >that</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row9_col1\" class=\"data row9 col1\" >1256</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row10_col0\" class=\"data row10 col0\" >of</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row10_col1\" class=\"data row10 col1\" >1159</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row11_col0\" class=\"data row11 col0\" >for</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row11_col1\" class=\"data row11 col1\" >1149</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row12_col0\" class=\"data row12 col0\" >are</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row12_col1\" class=\"data row12 col1\" >1128</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row13_col0\" class=\"data row13 col0\" >this</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row13_col1\" class=\"data row13 col1\" >1110</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row14_col0\" class=\"data row14 col0\" >in</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row14_col1\" class=\"data row14 col1\" >954</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row15_col0\" class=\"data row15 col0\" >me</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row15_col1\" class=\"data row15 col1\" >902</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row16_col0\" class=\"data row16 col0\" >my</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row16_col1\" class=\"data row16 col1\" >890</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row17_col0\" class=\"data row17 col0\" >am</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row17_col1\" class=\"data row17 col1\" >836</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row18_col0\" class=\"data row18 col0\" >so</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row18_col1\" class=\"data row18 col1\" >787</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row19_col0\" class=\"data row19 col0\" >do</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row19_col1\" class=\"data row19 col1\" >783</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row20_col0\" class=\"data row20 col0\" >have</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row20_col1\" class=\"data row20 col1\" >777</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row21_col0\" class=\"data row21 col0\" >your</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row21_col1\" class=\"data row21 col1\" >697</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row22_col0\" class=\"data row22 col0\" >be</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row22_col1\" class=\"data row22 col1\" >678</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row23_col0\" class=\"data row23 col0\" >we</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row23_col1\" class=\"data row23 col1\" >665</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row24_col0\" class=\"data row24 col0\" >but</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row24_col1\" class=\"data row24 col1\" >637</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row25_col0\" class=\"data row25 col0\" >on</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row25_col1\" class=\"data row25 col1\" >629</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row26_col0\" class=\"data row26 col0\" >like</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row26_col1\" class=\"data row26 col1\" >588</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row27_col0\" class=\"data row27 col0\" >all</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row27_col1\" class=\"data row27 col1\" >571</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row28_col0\" class=\"data row28 col0\" >just</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row28_col1\" class=\"data row28 col1\" >538</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row29_col0\" class=\"data row29 col0\" >will</td>\n",
              "                        <td id=\"T_b6862c74_b55d_11ea_a504_0242ac1c0002row29_col1\" class=\"data row29 col1\" >534</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f92b9d1ea58>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lHX0Rwb6isx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for t in tweets:\n",
        "    for idx,token in enumerate(t['text_clean']):\n",
        "        if token in special:\n",
        "            t['text_clean'][idx] = special[token]\n",
        "        if token in emoji_remain_text:\n",
        "            t['text_clean'][idx] = re.sub(\"_\", \" \",re.sub(':','',emoji.demojize(token)))\n",
        "    for idx,token in enumerate(t['reply_clean']):\n",
        "        if token in special:\n",
        "            t['reply_clean'][idx] = special[token]\n",
        "        if token in emoji_remain_reply:\n",
        "            t['reply_clean'][idx] = re.sub(\"_\", \" \",re.sub(':','',emoji.demojize(token)))\n",
        "    #t['text_clean'] = [c for c in t['text_clean'] if c not in weird]\n",
        "    #t['reply_clean'] = [c for c in t['reply_clean'] if c not in weird]\n",
        "for t in dev:\n",
        "    for idx,token in enumerate(t['text_clean']):\n",
        "        if token in special:\n",
        "            t['text_clean'][idx] = special[token]\n",
        "        if token in emoji_remain_text:\n",
        "            t['text_clean'][idx] = re.sub(\"_\", \" \",re.sub(':','',emoji.demojize(token)))\n",
        "    for idx,token in enumerate(t['reply_clean']):\n",
        "        if token in special:\n",
        "            t['reply_clean'][idx] = special[token]\n",
        "        if token in emoji_remain_reply:\n",
        "            t['reply_clean'][idx] = re.sub(\"_\", \" \",re.sub(':','',emoji.demojize(token)))\n",
        "    #t['text_clean'] = [c for c in t['text_clean'] if c not in weird]\n",
        "    #t['reply_clean'] = [c for c in t['reply_clean'] if c not in weird]\n",
        "for t in test:\n",
        "    for idx,token in enumerate(t['text_clean']):\n",
        "        if token in special:\n",
        "            t['text_clean'][idx] = special[token]\n",
        "        if token in emoji_remain_text:\n",
        "            t['text_clean'][idx] = re.sub(\"_\", \" \",re.sub(':','',emoji.demojize(token)))\n",
        "    for idx,token in enumerate(t['reply_clean']):\n",
        "        if token in special:\n",
        "            t['reply_clean'][idx] = special[token]\n",
        "        if token in emoji_remain_reply:\n",
        "            t['reply_clean'][idx] = re.sub(\"_\", \" \",re.sub(':','',emoji.demojize(token)))\n",
        "    #t['text_clean'] = [c for c in t['text_clean'] if c not in weird]\n",
        "    #t['reply_clean'] = [c for c in t['reply_clean'] if c not in weird]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx1lQp3d7N7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_index = {}\n",
        "for idx,c in enumerate(categories):\n",
        "    cat_index[c]=idx\n",
        "    \n",
        "def cat2vec(cat):\n",
        "    res = []\n",
        "    for tweet in cat:\n",
        "        temp = np.zeros(43)\n",
        "        for c in tweet:\n",
        "            temp[cat_index[c]] = 1\n",
        "        res.append(temp)\n",
        "    return np.array(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZCAGLY86rjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets[25376]['text_clean'] = tweets[25376]['text_clean'][3:]\n",
        "train_text = [\" \".join(t['text_clean']) for t in tweets]\n",
        "tweets[28767]['reply_clean'] = tweets[28767]['reply_clean'][:90]\n",
        "train_reply = [\" \".join(t['reply_clean']) for t in tweets]\n",
        "train_y = [t['categories'] for t in tweets]\n",
        "\n",
        "\n",
        "dev[1581]['text_clean'] = dev[1581]['text_clean'][5:]\n",
        "dev_text = [\" \".join(t['text_clean']) for t in dev]\n",
        "dev_reply = [\" \".join(t['reply_clean']) for t in dev]\n",
        "\n",
        "test[2949]['reply_clean'] = test[2949]['reply_clean'][:25]\n",
        "test[1487]['text_clean'] = test[1487]['text_clean'][8:]\n",
        "test_text = [\" \".join(t['text_clean']) for t in test]\n",
        "test_reply = [\" \".join(t['reply_clean']) for t in test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou47jbZP6-gb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ccc8420f-4188-4c8a-8ccb-38c766065a50"
      },
      "source": [
        "train_y = cat2vec(train_y)\n",
        "train_y[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwiEo_Ovr1Fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dict = {}\n",
        "for i in range(32000):\n",
        "  temp = train_text[i]+train_reply[i]\n",
        "  if temp in train_dict:\n",
        "    train_dict[temp].append((train_y[i],i))\n",
        "  else:\n",
        "    train_dict[temp] = [(train_y[i],i)]\n",
        "\n",
        "duplicated = []\n",
        "for key in train_dict:\n",
        "  if len(train_dict[key])>1:\n",
        "    for id in train_dict[key][1:]:\n",
        "      duplicated.append(id[1])\n",
        "\n",
        "new = []\n",
        "for key in train_dict:\n",
        "  if len(train_dict[key])>1:\n",
        "    first_idx = train_dict[key][0][1]\n",
        "    temp = np.zeros(43)\n",
        "    for id in train_dict[key]:\n",
        "      temp = np.logical_or(temp, id[0])\n",
        "    temp = temp.astype(int)\n",
        "    new.append((first_idx,temp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUfHtI67WWOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for idx, cat in new:\n",
        "  train_y[idx] = cat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6_g2OWbsgBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7b626efa-0ec4-47cc-cdb7-bc07e1842c19"
      },
      "source": [
        "print('before: ',len(train_text), len(train_reply), len(train_y))\n",
        "_tweets = np.delete(tweets, duplicated)\n",
        "train_text = np.delete(train_text, duplicated)\n",
        "train_reply = np.delete(train_reply, duplicated)\n",
        "train_y = np.delete(train_y, duplicated, axis=0)\n",
        "print('after: ',len(train_text), len(train_reply), len(train_y), len(_tweets))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before:  32000 32000 32000\n",
            "after:  26967 26967 26967 26967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21OTqkO1NggU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "073ac9b7dca24c64901109270f237d3f",
            "7b2619e0b32340c68c8fde7f9e76faec",
            "ab7ce8dfd8c743a180625fe54eb72a80",
            "2f299ab1513d4041ba26fa2c28d5d2fa",
            "76042d020ab644f7b82e8295e7b80843",
            "6862e620ac4d4caebe9e8430ca197720",
            "2a76e2d367d641fdb00dc6022be98e6c",
            "654d25fa9dea4420a8b2b6321cec695c"
          ]
        },
        "outputId": "e848c5b0-3b05-430e-f3b9-dba715996479"
      },
      "source": [
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
        "#tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "073ac9b7dca24c64901109270f237d3f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHW5_UJt7pXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = []\n",
        "for i in range(len(train_text)):\n",
        "  train_x.append(tokenizer.encode(train_text[i], train_reply[i],skip_special_tokens=True))\n",
        "\n",
        "dev_x = []\n",
        "for i in range(len(dev_text)):\n",
        "  dev_x.append(tokenizer.encode(dev_text[i], dev_reply[i],skip_special_tokens=True))\n",
        "\n",
        "test_x = []\n",
        "for i in range(len(test_text)):\n",
        "  test_x.append(tokenizer.encode(test_text[i], test_reply[i],skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOUElz6jTbV8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "670deb12-899b-435e-ea32-b83ca391d6f8"
      },
      "source": [
        "print(len(max(train_x,key=len)))\n",
        "print(len(max(dev_x,key=len)))\n",
        "print(len(max(test_x,key=len)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "205\n",
            "207\n",
            "207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdvM7UkmZnpi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "d9dfec11-6082-43ad-f156-95c646839b7b"
      },
      "source": [
        "gg = []\n",
        "for idx,t in enumerate(train_x):\n",
        "  gg.append((len(t),idx))\n",
        "sorted(gg,key=lambda x:x[0],reverse=True)[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(205, 15112),\n",
              " (204, 24351),\n",
              " (201, 21609),\n",
              " (151, 26300),\n",
              " (144, 13611),\n",
              " (143, 18680),\n",
              " (142, 16224),\n",
              " (138, 15868),\n",
              " (137, 12215),\n",
              " (137, 13504)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiOBXPJP_t-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 210"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNDvof9Z_aEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_mask = []\n",
        "for t in train_x:\n",
        "  N = len(t)\n",
        "  attention_mask.append(list(np.ones(N, dtype=int))+list(np.zeros(MAX_LEN-N, dtype=int)))\n",
        "\n",
        "attention_mask_d = []\n",
        "for t in dev_x:\n",
        "  N = len(t)\n",
        "  attention_mask_d.append(list(np.ones(N, dtype=int))+list(np.zeros(MAX_LEN-N, dtype=int)))\n",
        "\n",
        "attention_mask_t = []\n",
        "for t in test_x:\n",
        "  N = len(t)\n",
        "  attention_mask_t.append(list(np.ones(N, dtype=int))+list(np.zeros(MAX_LEN-N, dtype=int)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4RmRSZTDuwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_mask = np.mat(attention_mask)\n",
        "attention_mask_d = np.mat(attention_mask_d)\n",
        "attention_mask_t = np.mat(attention_mask_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNpQ6MYu-iG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = pad_sequences(train_x,  maxlen=MAX_LEN, dtype='int', padding='post', value = 5)\n",
        "dev_x = pad_sequences(dev_x,  maxlen=MAX_LEN, dtype='int', padding='post', value = 5)\n",
        "test_x = pad_sequences(test_x,  maxlen=MAX_LEN, dtype='int', padding='post', value = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcwPwA0UAf9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_type_ids = np.zeros((train_x.shape[0],MAX_LEN))\n",
        "token_type_ids_d = np.zeros((dev_x.shape[0],MAX_LEN))\n",
        "token_type_ids_t = np.zeros((test_x.shape[0],MAX_LEN))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uI27jRd8UmJ",
        "colab_type": "text"
      },
      "source": [
        "## Build XLNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZV35EkAzloN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "\n",
        "    config = XLNetConfig.from_pretrained('xlnet-base-cased', num_labels=43)\n",
        "    xlnet_model = TFXLNetForSequenceClassification.from_pretrained('xlnet-base-cased',config=config)\n",
        "    x = xlnet_model(ids,attention_mask=att,token_type_ids=tok)\n",
        "    \n",
        "    x1 = tf.keras.layers.Dropout(0.1)(x[0]) \n",
        "    x1 = tf.keras.layers.Dense(43)(x1)\n",
        "    x1 = tf.keras.layers.Activation('sigmoid')(x1)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=x1)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5rocE1Mwtoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model_large():\n",
        "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "\n",
        "    config = XLNetConfig.from_pretrained('xlnet-large-cased', num_labels=43)\n",
        "    xlnet_model = TFXLNetForSequenceClassification.from_pretrained('xlnet-large-cased',config=config)\n",
        "    x = xlnet_model(ids,attention_mask=att,token_type_ids=tok)\n",
        "    \n",
        "    x1 = tf.keras.layers.Dropout(0.1)(x[0]) \n",
        "    x1 = tf.keras.layers.Dense(43)(x1)\n",
        "    x1 = tf.keras.layers.Activation('sigmoid')(x1)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=x1)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hzt8tTc97_pP",
        "colab_type": "text"
      },
      "source": [
        "### XLNet(Base)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvOYZcjuCjt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "model.fit([train_x, attention_mask, token_type_ids], train_y, epochs=5, batch_size=32, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-lxJLRM8CLN",
        "colab_type": "text"
      },
      "source": [
        "### XLNet (Large)\n",
        "> failed, MAXLEN=145, batch=16\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfU7CEEwxJGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_large = build_model_large()\n",
        "\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "model_large.fit([train_x, attention_mask, token_type_ids], train_y, epochs=4, batch_size=16, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWmSQv388JdO",
        "colab_type": "text"
      },
      "source": [
        "### Pred and Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6SrvDYoXtUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict([dev_x, attention_mask_d, token_type_ids_d])\n",
        "pred_t = model.predict([test_x, attention_mask_t, token_type_ids_t])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP5edQSyvskv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(PATH+'pred_xlnet_d.npy', 'wb') as f:\n",
        "    np.save(f, pred)\n",
        "\n",
        "with open(PATH+'pred_xlnet_t.npy', 'wb') as f:\n",
        "    np.save(f, pred_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c51hzUCB7qYs",
        "colab_type": "text"
      },
      "source": [
        "## Ensemble XLNet(Base)\n",
        "\n",
        "\n",
        "*   0-3 batchsize=32\n",
        "*   4-6 batchsize=16\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-RWGBE_B8G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "c8a6a81b-dba7-45b7-d685-0d51d90be31e"
      },
      "source": [
        "start = 4\n",
        "for i in range(start,start+10):\n",
        "  config = tf.compat.v1.ConfigProto()\n",
        "  config.gpu_options.allow_growth = True\n",
        "  model = build_model()\n",
        "  model.fit([train_x, attention_mask, token_type_ids], train_y, epochs=5, batch_size=16, verbose=1)\n",
        "  pred = model.predict([dev_x, attention_mask_d, token_type_ids_d])\n",
        "  pred_t = model.predict([test_x, attention_mask_t, token_type_ids_t])\n",
        "  with open(PATH+'pred_xlnet_demogize{}_d.npy'.format(i), 'wb') as f:\n",
        "    np.save(f, pred)\n",
        "\n",
        "  with open(PATH+'pred_xlnet_demogize{}_t.npy'.format(i), 'wb') as f:\n",
        "    np.save(f, pred_t)\n",
        "  del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification_1/transformer/mask_emb:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification_1/transformer/mask_emb:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification_1/transformer/mask_emb:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification_1/transformer/mask_emb:0'] when minimizing the loss.\n",
            "1686/1686 [==============================] - 1920s 1s/step - loss: 0.1869\n",
            "Epoch 2/5\n",
            "1686/1686 [==============================] - 1925s 1s/step - loss: 0.1529\n",
            "Epoch 3/5\n",
            "1686/1686 [==============================] - 1924s 1s/step - loss: 0.1442\n",
            "Epoch 4/5\n",
            "1686/1686 [==============================] - 1922s 1s/step - loss: 0.1366\n",
            "Epoch 5/5\n",
            "1686/1686 [==============================] - 1923s 1s/step - loss: 0.1291\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification_2/transformer/mask_emb:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification_2/transformer/mask_emb:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification_2/transformer/mask_emb:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification_2/transformer/mask_emb:0'] when minimizing the loss.\n",
            "1686/1686 [==============================] - 1925s 1s/step - loss: 0.1903\n",
            "Epoch 2/5\n",
            "1686/1686 [==============================] - 1924s 1s/step - loss: 0.1513\n",
            "Epoch 3/5\n",
            "1686/1686 [==============================] - 1925s 1s/step - loss: 0.1413\n",
            "Epoch 4/5\n",
            "1686/1686 [==============================] - 1925s 1s/step - loss: 0.1338\n",
            "Epoch 5/5\n",
            "1686/1686 [==============================] - 1925s 1s/step - loss: 0.1252\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification_3/transformer/mask_emb:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification_3/transformer/mask_emb:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification_3/transformer/mask_emb:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification_3/transformer/mask_emb:0'] when minimizing the loss.\n",
            "1686/1686 [==============================] - 1927s 1s/step - loss: 0.2115\n",
            "Epoch 2/5\n",
            "1686/1686 [==============================] - 1927s 1s/step - loss: 0.1547\n",
            "Epoch 3/5\n",
            "1686/1686 [==============================] - 1928s 1s/step - loss: 0.1449\n",
            "Epoch 4/5\n",
            "1686/1686 [==============================] - 1926s 1s/step - loss: 0.1368\n",
            "Epoch 5/5\n",
            "1686/1686 [==============================] - 1926s 1s/step - loss: 0.1290\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification_4/transformer/mask_emb:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification_4/transformer/mask_emb:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification_4/transformer/mask_emb:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification_4/transformer/mask_emb:0'] when minimizing the loss.\n",
            "1686/1686 [==============================] - 1924s 1s/step - loss: 0.1891\n",
            "Epoch 2/5\n",
            "1686/1686 [==============================] - 1924s 1s/step - loss: 0.1531\n",
            "Epoch 3/5\n",
            "1577/1686 [===========================>..] - ETA: 2:04 - loss: 0.1448"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMCcWlSJ3z1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = []\n",
        "pred_t = []\n",
        "start = 0\n",
        "end = 6\n",
        "for i in range(start, end+1):\n",
        "  with open(PATH+'pred_xlnet_demogize{}_d.npy'.format(i), 'rb') as f:\n",
        "    a = np.load(f)\n",
        "    pred.append(a)\n",
        "  with open(PATH+'pred_xlnet_demogize{}_t.npy'.format(i), 'rb') as f:\n",
        "    a = np.load(f)\n",
        "    pred_t.append(a)\n",
        "pred = np.mean(pred,axis=0)\n",
        "pred_t = np.mean(pred_t,axis=0)\n",
        "\n",
        "with open(PATH+'pred_xlnet_ensemble{}-{}_d.npy'.format(start,end), 'wb') as f:\n",
        "    np.save(f, pred)\n",
        "\n",
        "with open(PATH+'pred_xlnet_ensemble{}-{}_t.npy'.format(start,end), 'wb') as f:\n",
        "    np.save(f, pred_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-PiOcSIcAMF",
        "colab_type": "text"
      },
      "source": [
        "## Ensemble XLNet(Large)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC-_XEvtbhR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689,
          "referenced_widgets": [
            "4881d21ecac5468884d189cf702bb448",
            "a48fb94c1c5b4667a45a8388dfb4f0f7",
            "f6ca3678f2b34f4c96315e3b88b708d8",
            "a0249d49247c4c17874fd3fe408c65ec",
            "24e1aa0fc420480cbee2f0f56030c393",
            "0fd3436d31a14e599be84dd80f068b9c",
            "42093061640b41bab4f5336fa3f7b0e7",
            "76e452e5cffe449d9c537ce798a1ab0e",
            "4286fb4eac924a16a8b318ea3d829450",
            "1d93b7df2d7a4130b76070c8a5d1f406",
            "012682670a8e4dfabdd226062e7b4eee",
            "64a3e179cd9b4d11bccfb3c90939e9fc",
            "61f2f324b7b04003892fe60aed04f488",
            "6effcf865d704a4d8b9f91115d1ae7d5",
            "f45c1dd1ad09473c9160bf8c79792f8d",
            "435f325b3c6c41bb848ab481d6bbe464"
          ]
        },
        "outputId": "948f5091-505c-4f13-ac6a-a2c7849b99f7"
      },
      "source": [
        "start = 0\n",
        "for i in range(start,start+10):\n",
        "  config = tf.compat.v1.ConfigProto()\n",
        "  config.gpu_options.allow_growth = True\n",
        "  model = build_model_large()\n",
        "  model.fit([train_x, attention_mask, token_type_ids], train_y, epochs=5, batch_size=16, verbose=1)\n",
        "  pred = model.predict([dev_x, attention_mask_d, token_type_ids_d])\n",
        "  pred_t = model.predict([test_x, attention_mask_t, token_type_ids_t])\n",
        "  with open(PATH+'pred_xlnet_large{}_d.npy'.format(i), 'wb') as f:\n",
        "    np.save(f, pred)\n",
        "\n",
        "  with open(PATH+'pred_xlnet_large{}_t.npy'.format(i), 'wb') as f:\n",
        "    np.save(f, pred_t)\n",
        "  del model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4881d21ecac5468884d189cf702bb448",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=761.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4286fb4eac924a16a8b318ea3d829450",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1572621064.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
            "   8/1678 [..............................] - ETA: 29:33 - loss: 0.5889"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-05ba590efd8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model_large\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids_d\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mpred_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[145,16,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model/tfxl_net_for_sequence_classification/transformer/transpose_3/transpose (defined at <ipython-input-40-05ba590efd8e>:6) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_57527]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcxdfqwxcGPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = []\n",
        "pred_t = []\n",
        "start = 0\n",
        "end = 3\n",
        "for i in range(start, end+1):\n",
        "  with open(PATH+'pred_xlnet_large{}_d.npy'.format(i), 'rb') as f:\n",
        "    a = np.load(f)\n",
        "    pred.append(a)\n",
        "  with open(PATH+'pred_xlnet_large{}_t.npy'.format(i), 'rb') as f:\n",
        "    a = np.load(f)\n",
        "    pred_t.append(a)\n",
        "pred = np.mean(pred,axis=0)\n",
        "pred_t = np.mean(pred_t,axis=0)\n",
        "\n",
        "with open(PATH+'pred_xlnet_large_ensemble{}-{}_d.npy'.format(start,end), 'wb') as f:\n",
        "    np.save(f, pred)\n",
        "\n",
        "with open(PATH+'pred_xlnet_large_ensemble{}-{}_t.npy'.format(start,end), 'wb') as f:\n",
        "    np.save(f, pred_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkrjKizy8Nre",
        "colab_type": "text"
      },
      "source": [
        "## Get Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEUg7jvYtU9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_cat(res):\n",
        "    ans = []\n",
        "    for r in res:\n",
        "        temp = [categories[i] for i in r]\n",
        "        ans.append(temp)\n",
        "    return ans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLSViCQ5rV0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = [np.argsort(res)[::-1][:6] for res in pred]\n",
        "results = decode_cat(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGBfdE5ItNA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for idx,t in enumerate(dev):\n",
        "    t['categories'] = results[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_P5wTdVtkKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev2 = []\n",
        "for line in open(PATH+'dev_unlabeled.json','r'):\n",
        "    dev2.append(json.loads(line))\n",
        "for idx,d in enumerate(dev):\n",
        "    dev2[idx]['categories']=d['categories']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eweRTxwtk8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in dev2:\n",
        "  with open('dev.json', 'a', encoding='utf-8') as f:\n",
        "    json.dump(i, f, ensure_ascii=False)\n",
        "    f.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG5eF8J7AtJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}